{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Cosmos DB and Python for the SQL API\n",
    "\n",
    "As you probably know, [Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/) is a globally distributed, multi-model database service in Azure that supports document, key-value, wide-column, and graph databases.\n",
    "\n",
    "Cosmos DB includes support for multiple Software Development Kits for programming languages such as Python. Multiple resources already exist that help to learn to use the Python SDK: \n",
    "\n",
    "* [Cosmos DB reference guide for the Python SDK](https://docs.microsoft.com/en-us/python/api/azure-cosmos/?view=azure-python)\n",
    "* [Cosmos DB samples with the Python SDK](https://github.com/Azure/azure-cosmos-python/blob/master/test/crud_tests.py)\n",
    "* [EDX course for Cosmos DB](https://courses.edx.org/courses/course-v1:Microsoft+DAT237x+2T2017/course/): most of the examples in this book come from this EDX course, feel free to go to the course to deepen in the concepts presented in this notebook.\n",
    "\n",
    "\n",
    "## Why a Jupyter Notebook?\n",
    "\n",
    "As opposed to documentation or code samples, Jupyter Notebooks offer a very interesting combination of rich text for explanations and pieces of code that can be executed independently from each other, which makes it ideal to learn a new technology.\n",
    "\n",
    "This notebook will go over the basic (and not so basic) concepts of using Cosmos DB with its Python SDK for the SQL API. You can run this repository from any system with Python 3.x, or using the free platform [Azure Notebooks](https://notebooks.azure.com/), where you have the option of importing Github repositories.\n",
    "\n",
    "Feel free to try some different variations of the code in this notebook, to see different effects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your Cosmos DB account\n",
    "\n",
    "All Cosmos databases are contained in a Cosmos DB account. You can create a Cosmos DB account in Azure using any Azure mechanism. In this notebook we will assume that you have installed the [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest), and use it to create a new resource group and a Cosmos DB account. But first things first, you need to login to Azure, and select the subscription you want to use\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"cloudName\": \"AzureCloud\",\n",
      "    \"homeTenantId\": \"16cbcec9-7692-45fc-babd-f69fef6a6eb2\",\n",
      "    \"id\": \"f85ee833-ccf2-4782-89eb-3e71f8e4d28d\",\n",
      "    \"isDefault\": true,\n",
      "    \"managedByTenants\": [],\n",
      "    \"name\": \"Subskrypcja platformy Azure 1\",\n",
      "    \"state\": \"Enabled\",\n",
      "    \"tenantId\": \"16cbcec9-7692-45fc-babd-f69fef6a6eb2\",\n",
      "    \"user\": {\n",
      "      \"name\": \"marcingrze@life.pl\",\n",
      "      \"type\": \"user\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: A web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s \"Subskrypcja platformy Azure 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now set some variables containing the name of the resource group we will use, the name of the Cosmos DB account to be created, the name for a database and for a collection. Consider that the name for your CosmosDB must be globally unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg         = \"cosmoslab\"\n",
    "location   = \"westeurope\"\n",
    "\n",
    "account    = \"mycosmos1138\"\n",
    "db_name    = \"ecommerce\"\n",
    "coll_name  = \"customers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create our resource group and Cosmos DB account. When creating the account there some attributes you can defined, such as the type of CosmosDB and API (in this case we will use the SQL API aka DocumentDB), the locations (in this example we will use only one region).\n",
    "\n",
    "Creating the account will take some minutes, please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"/subscriptions/f85ee833-ccf2-4782-89eb-3e71f8e4d28d/resourceGroups/cosmoslab\",\n",
      "  \"location\": \"westeurope\",\n",
      "  \"managedBy\": null,\n",
      "  \"name\": \"cosmoslab\",\n",
      "  \"properties\": {\n",
      "    \"provisioningState\": \"Succeeded\"\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.Resources/resourceGroups\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The regionName=failoverPriority method of specifying locations is deprecated. Use --locations KEY=VALUE [KEY=VALUE ...] to specify the regionName, failoverPriority, and isZoneRedundant properties of the location. Multiple locations can be specified by including more than one --locations argument.\n",
      "WARNING: Argument '--enable-free-tier' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\n",
      "ERROR: (ServiceUnavailable) Database account creation failed. Operation Id: 4ae3b559-1ffe-40e8-a79d-e9d29490be5a, Error : Message: {\"code\":\"ServiceUnavailable\",\"message\":\"Sorry, we are currently experiencing high demand in West Europe region, and cannot fulfill your request at this time. To request region access for your subscription, please follow this link https://aka.ms/cosmosdbquota for more details on how to create a region access request.\\r\\nActivityId: e927739a-00af-11ed-9769-9c5c8e70100d, Microsoft.Azure.Documents.Common/2.14.0\"}, Request URI: /serviceReservation, RequestStats: , SDK: Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0\n",
      "Code: ServiceUnavailable\n",
      "Message: Database account creation failed. Operation Id: 4ae3b559-1ffe-40e8-a79d-e9d29490be5a, Error : Message: {\"code\":\"ServiceUnavailable\",\"message\":\"Sorry, we are currently experiencing high demand in West Europe region, and cannot fulfill your request at this time. To request region access for your subscription, please follow this link https://aka.ms/cosmosdbquota for more details on how to create a region access request.\\r\\nActivityId: e927739a-00af-11ed-9769-9c5c8e70100d, Microsoft.Azure.Documents.Common/2.14.0\"}, Request URI: /serviceReservation, RequestStats: , SDK: Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0, Microsoft.Azure.Documents.Common/2.14.0\n"
     ]
    }
   ],
   "source": [
    "!az group create -n \"$rg\" -l \"$location\"\n",
    "!az cosmosdb create -g \"$rg\" -n \"$account\" --locations \"$location\"=0 --kind GlobalDocumentDB --enable-free-tier true --default-consistency-level \"Session\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Cosmos DB account\n",
    "\n",
    "After creating an account, you can modify it, for example to add new read or write regions. In this example we will add a second read region with a failover priority of 1. Note other interesting attributes, such as the default consistency level (session) or different failover properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!az cosmosdb update -g \"$rg\" -n \"$account\" --locations \"$location\"=0 northeurope=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have a look at the help for the `az cosmosdb update` command for more options to update existing Cosmos DB accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Command\n",
      "    az cosmosdb update : Update an Azure Cosmos DB database account.\n",
      "\n",
      "Arguments\n",
      "    --capabilities                               : Set custom capabilities on the Cosmos DB database\n",
      "                                                   account.\n",
      "    --default-consistency-level                  : Default consistency level of the Cosmos DB\n",
      "                                                   database account.  Allowed values:\n",
      "                                                   BoundedStaleness, ConsistentPrefix, Eventual,\n",
      "                                                   Session, Strong.\n",
      "    --default-identity                 [Preview] : The primary identity to access key vault in CMK\n",
      "                                                   related features. e.g. 'FirstPartyIdentity',\n",
      "                                                   'SystemAssignedIdentity' and more.\n",
      "        WARNING: Argument '--default-identity' is in preview and under development. Reference and\n",
      "        support levels: https://aka.ms/CLI_refstatus\n",
      "    --disable-key-based-metadata-write-access    : Disable write operations on metadata resources\n",
      "                                                   (databases, containers, throughput) via account\n",
      "                                                   keys.  Allowed values: false, true.\n",
      "    --enable-analytical-storage                  : Flag to enable log storage on the account.\n",
      "                                                   Allowed values: false, true.\n",
      "    --enable-automatic-failover                  : Enables automatic failover of the write region in\n",
      "                                                   the rare event that the region is unavailable due\n",
      "                                                   to an outage. Automatic failover will result in a\n",
      "                                                   new write region for the account and is chosen\n",
      "                                                   based on the failover priorities configured for\n",
      "                                                   the account.  Allowed values: false, true.\n",
      "    --enable-multiple-write-locations            : Enable Multiple Write Locations.  Allowed values:\n",
      "                                                   false, true.\n",
      "    --enable-public-network -e                   : Enable or disable public network access to\n",
      "                                                   server.  Allowed values: false, true.\n",
      "    --enable-virtual-network                     : Enables virtual network on the Cosmos DB database\n",
      "                                                   account.  Allowed values: false, true.\n",
      "    --ip-range-filter                            : Firewall support. Specifies the set of IP\n",
      "                                                   addresses or IP address ranges in CIDR form to be\n",
      "                                                   included as the allowed list of client IPs for a\n",
      "                                                   given database account. IP addresses/ranges must\n",
      "                                                   be comma-separated and must not contain any\n",
      "                                                   spaces.\n",
      "    --key-uri                          [Preview] : The URI of the key vault.\n",
      "        WARNING: Argument '--key-uri' is in preview and under development. Reference and support\n",
      "        levels: https://aka.ms/CLI_refstatus\n",
      "    --locations                                  : Add a location to the Cosmos DB database account.\n",
      "        Usage:          --locations KEY=VALUE [KEY=VALUE ...]\n",
      "        Required Keys:  regionName, failoverPriority\n",
      "        Optional Key:   isZoneRedundant\n",
      "        Default:        single region account in the location of the specified resource group.\n",
      "        Failover priority values are 0 for write regions and greater than 0 for read regions. A\n",
      "        failover priority value must be unique and less than the total number of regions.\n",
      "        Multiple locations can be specified by using more than one `--locations` argument.\n",
      "    --max-interval                               : When used with Bounded Staleness consistency,\n",
      "                                                   this value represents the time amount of\n",
      "                                                   staleness (in seconds) tolerated. Accepted range\n",
      "                                                   for this value is 5 - 86400.\n",
      "    --max-staleness-prefix                       : When used with Bounded Staleness consistency,\n",
      "                                                   this value represents the number of stale\n",
      "                                                   requests tolerated. Accepted range for this value\n",
      "                                                   is 10 - 2,147,483,647.\n",
      "    --network-acl-bypass                         : Flag to enable or disable Network Acl Bypass.\n",
      "                                                   Allowed values: AzureServices, None.\n",
      "    --network-acl-bypass-resource-ids -i         : List of Resource Ids to allow Network Acl Bypass.\n",
      "    --server-version                   [Preview] : Valid only for MongoDB accounts.  Allowed values:\n",
      "                                                   3.2, 3.6, 4.0, 4.2.\n",
      "        WARNING: Argument '--server-version' is in preview and under development. Reference and\n",
      "        support levels: https://aka.ms/CLI_refstatus\n",
      "    --tags                                       : Space-separated tags: key[=value] [key[=value]\n",
      "                                                   ...]. Use \"\" to clear existing tags.\n",
      "    --virtual-network-rules                      : ACL's for virtual network.\n",
      "\n",
      "Analytical Storage Configuration Arguments\n",
      "    --analytical-storage-schema-type --as-schema : Schema type for analytical storage.  Allowed\n",
      "                                                   values: FullFidelity, WellDefined.\n",
      "\n",
      "Backup Policy Arguments\n",
      "    --backup-interval                            : The frequency(in minutes) with which backups are\n",
      "                                                   taken (only for accounts with periodic mode\n",
      "                                                   backups).\n",
      "    --backup-policy-type                         : The type of backup policy of the account to\n",
      "                                                   create.  Allowed values: Continuous, Periodic.\n",
      "    --backup-redundancy                          : The redundancy type of the backup Storage\n",
      "                                                   account.  Allowed values: Geo, Local, Zone.\n",
      "    --backup-retention                           : The time(in hours) for which each backup is\n",
      "                                                   retained (only for accounts with periodic mode\n",
      "                                                   backups).\n",
      "\n",
      "Resource Id Arguments\n",
      "    --ids                                        : One or more resource IDs (space-delimited). It\n",
      "                                                   should be a complete resource ID containing all\n",
      "                                                   information of 'Resource Id' arguments. You\n",
      "                                                   should provide either --ids or other 'Resource\n",
      "                                                   Id' arguments.\n",
      "    --name -n                                    : Name of the Cosmos DB database account.\n",
      "    --resource-group -g                          : Name of resource group. You can configure the\n",
      "                                                   default group using `az configure --defaults\n",
      "                                                   group=<name>`.\n",
      "    --subscription                               : Name or ID of subscription. You can configure the\n",
      "                                                   default subscription using `az account set -s\n",
      "                                                   NAME_OR_ID`.\n",
      "\n",
      "Global Arguments\n",
      "    --debug                                      : Increase logging verbosity to show all debug\n",
      "                                                   logs.\n",
      "    --help -h                                    : Show this help message and exit.\n",
      "    --only-show-errors                           : Only show errors, suppressing warnings.\n",
      "    --output -o                                  : Output format.  Allowed values: json, jsonc,\n",
      "                                                   none, table, tsv, yaml, yamlc.  Default: json.\n",
      "    --query                                      : JMESPath query string. See http://jmespath.org/\n",
      "                                                   for more information and examples.\n",
      "    --verbose                                    : Increase logging verbosity. Use --debug for full\n",
      "                                                   debug logs.\n",
      "\n",
      "Examples\n",
      "    Update an Azure Cosmos DB database account. (autogenerated)\n",
      "        az cosmosdb update --capabilities EnableGremlin --name MyCosmosDBDatabaseAccount --resource-\n",
      "        group MyResourceGroup\n",
      "\n",
      "    Creates a new Azure Cosmos DB database account with two regions. UK South is zone redundant.\n",
      "        az cosmosdb update -n myaccount -g mygroup --locations regionName=eastus failoverPriority=0\n",
      "        isZoneRedundant=False --locations regionName=uksouth failoverPriority=1 isZoneRedundant=True\n",
      "        --enable-multiple-write-locations --network-acl-bypass AzureServices --network-acl-bypass-\n",
      "        resource-ids\n",
      "        /subscriptions/subId/resourceGroups/rgName/providers/Microsoft.Synapse/workspaces/wsName\n",
      "\n",
      "To search AI knowledge base for examples, use: az find \"az cosmosdb update\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please let us know how we are doing: https://aka.ms/azureclihats\n"
     ]
    }
   ],
   "source": [
    "!az cosmosdb update -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Authentication to a Cosmos DB account works using an account key. There are two account keys for key rotation. You can use the Azure CLI to get the key for an existing account, in this case we get the primary key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_key = !az cosmosdb list-keys -g $rg -n $account --query primaryMasterKey -o tsv\n",
    "# Per default the output is a list, keep only the first item\n",
    "account_key = str(account_key[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client\n",
    "\n",
    "You can create databases and collections using the Azure CLI too, or using the Python SDK already. Since this notebook is about Python, let us use the Python SDK already for this.\n",
    "\n",
    "The first thing we need is to initialize the client, with the Cosmos DB account endpoint (that you can derive from the name, or use the Azure CLI to find out), and the master key that we already got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mycosmos1138.documents.azure.com\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Building the endpoint as a string\n",
    "cosmosdb_endpoint = \"https://{0}.documents.azure.com\".format(account)\n",
    "print(cosmosdb_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: (ResourceNotFound) The Resource 'Microsoft.DocumentDB/databaseAccounts/mycosmos1138' under resource group 'cosmoslab' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Getting the endpoint with the Azure CLI\n",
    "cosmosdb_endpoint = ! az cosmosdb show -g $rg -n $account --query documentEndpoint -o tsv\n",
    "cosmosdb_endpoint = str(cosmosdb_endpoint[0])\n",
    "print(cosmosdb_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before initializaing the client, let us make sure that we have all required Python dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure\n",
      "  Using cached azure-5.0.0.zip (4.6 kB)\n",
      "  Using cached azure-4.0.0-py2.py3-none-any.whl (2.2 kB)\n",
      "Collecting azure-cosmos\n",
      "  Using cached azure_cosmos-4.3.0-py3-none-any.whl (215 kB)\n",
      "Collecting azure-mgmt~=4.0\n",
      "  Using cached azure_mgmt-4.0.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting azure-loganalytics~=0.1.0\n",
      "  Using cached azure_loganalytics-0.1.1-py2.py3-none-any.whl (16 kB)\n",
      "Collecting azure-storage-file~=1.3\n",
      "  Using cached azure_storage_file-1.4.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting azure-servicebus~=0.21.1\n",
      "  Using cached azure_servicebus-0.21.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-graphrbac~=0.40.0\n",
      "  Using cached azure_graphrbac-0.40.0-py2.py3-none-any.whl (63 kB)\n",
      "Collecting azure-keyvault~=1.0\n",
      "  Using cached azure_keyvault-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Collecting azure-applicationinsights~=0.1.0\n",
      "  Using cached azure_applicationinsights-0.1.1-py2.py3-none-any.whl (103 kB)\n",
      "Collecting azure-storage-queue~=1.3\n",
      "  Using cached azure_storage_queue-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting azure-storage-blob~=1.3\n",
      "  Using cached azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting azure-cosmosdb-table~=1.0\n",
      "  Using cached azure_cosmosdb_table-1.0.6-py2.py3-none-any.whl (125 kB)\n",
      "Collecting azure-servicefabric~=6.3.0.0\n",
      "  Using cached azure_servicefabric-6.3.0.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting azure-eventgrid~=1.1\n",
      "  Using cached azure_eventgrid-1.3.0-py2.py3-none-any.whl (167 kB)\n",
      "Collecting azure-batch~=4.1\n",
      "  Using cached azure_batch-4.1.3-py2.py3-none-any.whl (314 kB)\n",
      "Collecting azure-servicemanagement-legacy~=0.20.6\n",
      "  Using cached azure_servicemanagement_legacy-0.20.7-py2.py3-none-any.whl (75 kB)\n",
      "Collecting azure-datalake-store~=0.0.18\n",
      "  Using cached azure_datalake_store-0.0.52-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-cosmos->-r requirements.txt (line 2)) (1.24.2)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (1.1.28)\n",
      "Requirement already satisfied: msrestazure<2.0.0,>=0.4.20 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-batch~=4.1->azure->-r requirements.txt (line 1)) (0.6.4)\n",
      "Requirement already satisfied: azure-nspkg>=2.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-batch~=4.1->azure->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (4.1.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-cosmosdb-table~=1.0->azure->-r requirements.txt (line 1)) (2.8.2)\n",
      "Collecting azure-cosmosdb-nspkg>=2.0.0\n",
      "  Using cached azure_cosmosdb_nspkg-2.0.2-py2.py3-none-any.whl (2.9 kB)\n",
      "Requirement already satisfied: cryptography in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-cosmosdb-table~=1.0->azure->-r requirements.txt (line 1)) (3.4.8)\n",
      "Requirement already satisfied: cffi in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: adal>=0.4.2 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (1.2.7)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from adal>=0.4.2->azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: azure-mgmt-servicebus~=0.5.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.5.3)\n",
      "Collecting azure-mgmt-iotcentral~=0.1.0\n",
      "  Using cached azure_mgmt_iotcentral-0.1.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting azure-mgmt-devspaces~=0.1.0\n",
      "  Using cached azure_mgmt_devspaces-0.1.0-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: azure-mgmt-policyinsights~=0.1.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: azure-mgmt-servicefabric~=0.2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: azure-mgmt-subscription~=0.2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.2.0)\n",
      "Collecting azure-mgmt-datalake-analytics~=0.6.0\n",
      "  Using cached azure_mgmt_datalake_analytics-0.6.0-py2.py3-none-any.whl (288 kB)\n",
      "Collecting azure-mgmt-advisor~=1.0\n",
      "  Using cached azure_mgmt_advisor-1.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting azure-mgmt-billing~=0.2.0\n",
      "  Using cached azure_mgmt_billing-0.2.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azure-mgmt-cognitiveservices~=3.0\n",
      "  Using cached azure_mgmt_cognitiveservices-3.0.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azure-mgmt-managementpartner~=0.1.0\n",
      "  Using cached azure_mgmt_managementpartner-0.1.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting azure-mgmt-batchai~=2.0\n",
      "  Using cached azure_mgmt_batchai-2.0.0-py2.py3-none-any.whl (174 kB)\n",
      "Collecting azure-mgmt-loganalytics~=0.2.0\n",
      "  Using cached azure_mgmt_loganalytics-0.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting azure-mgmt-keyvault~=1.0\n",
      "  Using cached azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-mgmt-maps~=0.1.0\n",
      "  Using cached azure_mgmt_maps-0.1.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting azure-mgmt-eventgrid~=1.0\n",
      "  Using cached azure_mgmt_eventgrid-1.0.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting azure-mgmt-logic~=3.0\n",
      "  Using cached azure_mgmt_logic-3.0.0-py2.py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: azure-mgmt-search~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: azure-mgmt-signalr~=0.1.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.1.1)\n",
      "Collecting azure-mgmt-authorization~=0.50.0\n",
      "  Using cached azure_mgmt_authorization-0.50.0-py2.py3-none-any.whl (81 kB)\n",
      "Collecting azure-mgmt-media~=1.0.0rc2\n",
      "  Using cached azure_mgmt_media-1.0.1-py2.py3-none-any.whl (335 kB)\n",
      "Requirement already satisfied: azure-mgmt-powerbiembedded~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: azure-mgmt-redis~=5.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (5.0.0)\n",
      "Collecting azure-mgmt-msi~=0.2.0\n",
      "  Using cached azure_mgmt_msi-0.2.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: azure-mgmt-web~=0.35.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.35.0)\n",
      "Requirement already satisfied: azure-mgmt-network~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.7.0)\n",
      "Collecting azure-mgmt-compute~=4.0\n",
      "  Using cached azure_mgmt_compute-4.6.2-py2.py3-none-any.whl (3.0 MB)\n",
      "Collecting azure-mgmt-consumption~=2.0\n",
      "  Using cached azure_mgmt_consumption-2.0.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting azure-mgmt-dns~=2.0\n",
      "  Using cached azure_mgmt_dns-2.1.0-py2.py3-none-any.whl (134 kB)\n",
      "Collecting azure-mgmt-datafactory~=0.6.0\n",
      "  Using cached azure_mgmt_datafactory-0.6.0-py2.py3-none-any.whl (418 kB)\n",
      "Collecting azure-mgmt-commerce~=1.0\n",
      "  Using cached azure_mgmt_commerce-1.0.1-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azure-mgmt-iothub~=0.5.0\n",
      "  Using cached azure_mgmt_iothub-0.5.0-py2.py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: azure-mgmt-relay~=0.1.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.1.0)\n",
      "Collecting azure-mgmt-batch~=5.0\n",
      "  Using cached azure_mgmt_batch-5.0.1-py2.py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: azure-mgmt-resource~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.2.0)\n",
      "Collecting azure-mgmt-containerinstance~=1.0\n",
      "  Using cached azure_mgmt_containerinstance-1.5.0-py2.py3-none-any.whl (96 kB)\n",
      "Collecting azure-mgmt-cdn~=3.0\n",
      "  Using cached azure_mgmt_cdn-3.1.0-py2.py3-none-any.whl (119 kB)\n",
      "Requirement already satisfied: azure-mgmt-rdbms~=1.2 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: azure-mgmt-recoveryservices~=0.3.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: azure-mgmt-storage~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: azure-mgmt-sql~=0.9.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.9.1)\n",
      "Collecting azure-mgmt-containerregistry~=2.1\n",
      "  Using cached azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azure-mgmt-datamigration~=1.0\n",
      "  Using cached azure_mgmt_datamigration-1.0.0-py2.py3-none-any.whl (185 kB)\n",
      "Collecting azure-mgmt-hanaonazure~=0.1.1\n",
      "  Using cached azure_mgmt_hanaonazure-0.1.1-py2.py3-none-any.whl (20 kB)\n",
      "Collecting azure-mgmt-datalake-store~=0.5.0\n",
      "  Using cached azure_mgmt_datalake_store-0.5.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting azure-mgmt-machinelearningcompute~=0.4.1\n",
      "  Using cached azure_mgmt_machinelearningcompute-0.4.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: azure-mgmt-reservations~=0.2.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: azure-mgmt-trafficmanager~=0.50.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.50.0)\n",
      "Collecting azure-mgmt-eventhub~=2.1\n",
      "  Using cached azure_mgmt_eventhub-2.6.0-py2.py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: azure-mgmt-recoveryservicesbackup~=0.3.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (0.3.0)\n",
      "Collecting azure-mgmt-iothubprovisioningservices~=0.2.0\n",
      "  Using cached azure_mgmt_iothubprovisioningservices-0.2.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting azure-mgmt-devtestlabs~=2.2\n",
      "  Using cached azure_mgmt_devtestlabs-2.2.0-py2.py3-none-any.whl (194 kB)\n",
      "Collecting azure-mgmt-marketplaceordering~=0.1.0\n",
      "  Using cached azure_mgmt_marketplaceordering-0.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting azure-mgmt-containerservice~=4.2\n",
      "  Using cached azure_mgmt_containerservice-4.4.0-py2.py3-none-any.whl (206 kB)\n",
      "Collecting azure-mgmt-applicationinsights~=0.1.1\n",
      "  Using cached azure_mgmt_applicationinsights-0.1.1-py2.py3-none-any.whl (42 kB)\n",
      "Collecting azure-mgmt-managementgroups~=0.1.0\n",
      "  Using cached azure_mgmt_managementgroups-0.1.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting azure-mgmt-monitor~=0.5.2\n",
      "  Using cached azure_mgmt_monitor-0.5.2-py2.py3-none-any.whl (247 kB)\n",
      "Requirement already satisfied: azure-mgmt-scheduler~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.0.0)\n",
      "Collecting azure-mgmt-cosmosdb~=0.4.1\n",
      "  Using cached azure_mgmt_cosmosdb-0.4.1-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: azure-mgmt-notificationhubs~=2.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: azure-mgmt-nspkg>=2.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt-advisor~=1.0->azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: azure-mgmt-datalake-nspkg>=2.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-mgmt-datalake-analytics~=0.6.0->azure-mgmt~=4.0->azure->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: azure-storage-common~=1.4 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-storage-blob~=1.3->azure->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\marci\\anaconda3\\lib\\site-packages (from cffi->azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (3.2.0)\n",
      "Installing collected packages: azure-mgmt-msi, azure-mgmt-monitor, azure-mgmt-media, azure-mgmt-marketplaceordering, azure-mgmt-maps, azure-mgmt-managementpartner, azure-mgmt-managementgroups, azure-mgmt-machinelearningcompute, azure-mgmt-logic, azure-mgmt-loganalytics, azure-mgmt-keyvault, azure-mgmt-iothubprovisioningservices, azure-mgmt-iothub, azure-mgmt-iotcentral, azure-mgmt-hanaonazure, azure-mgmt-eventhub, azure-mgmt-eventgrid, azure-mgmt-dns, azure-mgmt-devtestlabs, azure-mgmt-devspaces, azure-mgmt-datamigration, azure-mgmt-datalake-store, azure-mgmt-datalake-analytics, azure-mgmt-datafactory, azure-mgmt-cosmosdb, azure-mgmt-containerservice, azure-mgmt-containerregistry, azure-mgmt-containerinstance, azure-mgmt-consumption, azure-mgmt-compute, azure-mgmt-commerce, azure-mgmt-cognitiveservices, azure-mgmt-cdn, azure-mgmt-billing, azure-mgmt-batchai, azure-mgmt-batch, azure-mgmt-authorization, azure-mgmt-applicationinsights, azure-mgmt-advisor, azure-cosmosdb-nspkg, azure-storage-queue, azure-storage-file, azure-storage-blob, azure-servicemanagement-legacy, azure-servicefabric, azure-servicebus, azure-mgmt, azure-loganalytics, azure-keyvault, azure-graphrbac, azure-eventgrid, azure-datalake-store, azure-cosmosdb-table, azure-batch, azure-applicationinsights, azure-cosmos, azure\n",
      "Successfully installed azure-4.0.0 azure-applicationinsights-0.1.1 azure-batch-4.1.3 azure-cosmos-4.3.0 azure-cosmosdb-nspkg-2.0.2 azure-cosmosdb-table-1.0.6 azure-datalake-store-0.0.52 azure-eventgrid-1.3.0 azure-graphrbac-0.40.0 azure-keyvault-1.1.0 azure-loganalytics-0.1.1 azure-mgmt-4.0.0 azure-mgmt-advisor-1.0.1 azure-mgmt-applicationinsights-0.1.1 azure-mgmt-authorization-0.50.0 azure-mgmt-batch-5.0.1 azure-mgmt-batchai-2.0.0 azure-mgmt-billing-0.2.0 azure-mgmt-cdn-3.1.0 azure-mgmt-cognitiveservices-3.0.0 azure-mgmt-commerce-1.0.1 azure-mgmt-compute-4.6.2 azure-mgmt-consumption-2.0.0 azure-mgmt-containerinstance-1.5.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-containerservice-4.4.0 azure-mgmt-cosmosdb-0.4.1 azure-mgmt-datafactory-0.6.0 azure-mgmt-datalake-analytics-0.6.0 azure-mgmt-datalake-store-0.5.0 azure-mgmt-datamigration-1.0.0 azure-mgmt-devspaces-0.1.0 azure-mgmt-devtestlabs-2.2.0 azure-mgmt-dns-2.1.0 azure-mgmt-eventgrid-1.0.0 azure-mgmt-eventhub-2.6.0 azure-mgmt-hanaonazure-0.1.1 azure-mgmt-iotcentral-0.1.0 azure-mgmt-iothub-0.5.0 azure-mgmt-iothubprovisioningservices-0.2.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-loganalytics-0.2.0 azure-mgmt-logic-3.0.0 azure-mgmt-machinelearningcompute-0.4.1 azure-mgmt-managementgroups-0.1.0 azure-mgmt-managementpartner-0.1.1 azure-mgmt-maps-0.1.0 azure-mgmt-marketplaceordering-0.1.0 azure-mgmt-media-1.0.1 azure-mgmt-monitor-0.5.2 azure-mgmt-msi-0.2.0 azure-servicebus-0.21.1 azure-servicefabric-6.3.0.0 azure-servicemanagement-legacy-0.20.7 azure-storage-blob-1.5.0 azure-storage-file-1.4.0 azure-storage-queue-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\Users\\marci\\anaconda3\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\marci\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pw6j980c\\\\azure_ef2c40493ecf49d983dd137175dc9798\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\marci\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pw6j980c\\\\azure_ef2c40493ecf49d983dd137175dc9798\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\marci\\AppData\\Local\\Temp\\pip-pip-egg-info-7cb0dypx'\n",
      "         cwd: C:\\Users\\marci\\AppData\\Local\\Temp\\pip-install-pw6j980c\\azure_ef2c40493ecf49d983dd137175dc9798\\\n",
      "    Complete output (24 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\marci\\AppData\\Local\\Temp\\pip-install-pw6j980c\\azure_ef2c40493ecf49d983dd137175dc9798\\setup.py\", line 60, in <module>\n",
      "        raise RuntimeError(message)\n",
      "    RuntimeError:\n",
      "    \n",
      "    Starting with v5.0.0, the 'azure' meta-package is deprecated and cannot be installed anymore.\n",
      "    Please install the service specific packages prefixed by `azure` needed for your application.\n",
      "    \n",
      "    The complete list of available packages can be found at:\n",
      "    https://aka.ms/azsdk/python/all\n",
      "    \n",
      "    Here's a non-exhaustive list of common packages:\n",
      "    \n",
      "    -  azure-mgmt-compute (https://pypi.python.org/pypi/azure-mgmt-compute) : Management of Virtual Machines, etc.\n",
      "    -  azure-mgmt-storage (https://pypi.python.org/pypi/azure-mgmt-storage) : Management of storage accounts.\n",
      "    -  azure-mgmt-resource (https://pypi.python.org/pypi/azure-mgmt-resource) : Generic package about Azure Resource Management (ARM)\n",
      "    -  azure-keyvault-secrets (https://pypi.python.org/pypi/azure-keyvault-secrets) : Access to secrets in Key Vault\n",
      "    -  azure-storage-blob (https://pypi.python.org/pypi/azure-storage-blob) : Access to blobs in storage accounts\n",
      "    \n",
      "    A more comprehensive discussion of the rationale for this decision can be found in the following issue:\n",
      "    https://github.com/Azure/azure-sdk-for-python/issues/10646\n",
      "    \n",
      "    \n",
      "    ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/e8/48/ef73d5e71ecb84cacaeaf533f519be81825ad6198acc41bd821f440e7f7c/azure-5.0.0.zip#sha256=f56d22acaba0ce74b821fd3d012d18854f9d0b3662d5a3a9240b1bd587c96b23 (from https://pypi.org/simple/azure/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure\n",
      "  Downloading azure-5.0.0.zip (4.6 kB)\n",
      "  Downloading azure-4.0.0-py2.py3-none-any.whl (2.2 kB)\n",
      "Collecting azure-cosmos\n",
      "  Downloading azure_cosmos-4.3.0-py3-none-any.whl (215 kB)\n",
      "Collecting azure-servicebus~=0.21.1\n",
      "  Downloading azure_servicebus-0.21.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-eventgrid~=1.1\n",
      "  Downloading azure_eventgrid-1.3.0-py2.py3-none-any.whl (167 kB)\n",
      "Collecting azure-loganalytics~=0.1.0\n",
      "  Downloading azure_loganalytics-0.1.1-py2.py3-none-any.whl (16 kB)\n",
      "Collecting azure-cosmosdb-table~=1.0\n",
      "  Downloading azure_cosmosdb_table-1.0.6-py2.py3-none-any.whl (125 kB)\n",
      "Collecting azure-applicationinsights~=0.1.0\n",
      "  Downloading azure_applicationinsights-0.1.1-py2.py3-none-any.whl (103 kB)\n",
      "Collecting azure-servicefabric~=6.3.0.0\n",
      "  Downloading azure_servicefabric-6.3.0.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting azure-storage-file~=1.3\n",
      "  Downloading azure_storage_file-1.4.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting azure-mgmt~=4.0\n",
      "  Downloading azure_mgmt-4.0.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Collecting azure-datalake-store~=0.0.18\n",
      "  Downloading azure_datalake_store-0.0.52-py2.py3-none-any.whl (61 kB)\n",
      "Collecting azure-storage-queue~=1.3\n",
      "  Downloading azure_storage_queue-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting azure-keyvault~=1.0\n",
      "  Downloading azure_keyvault-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Collecting azure-servicemanagement-legacy~=0.20.6\n",
      "  Downloading azure_servicemanagement_legacy-0.20.7-py2.py3-none-any.whl (75 kB)\n",
      "Collecting azure-graphrbac~=0.40.0\n",
      "  Downloading azure_graphrbac-0.40.0-py2.py3-none-any.whl (63 kB)\n",
      "Collecting azure-storage-blob~=1.3\n",
      "  Downloading azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting azure-batch~=4.1\n",
      "  Downloading azure_batch-4.1.3-py2.py3-none-any.whl (314 kB)\n",
      "Collecting azure-core<2.0.0,>=1.23.0\n",
      "  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\n",
      "Collecting msrest>=0.6.21\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting msrestazure<2.0.0,>=0.4.20\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-nspkg>=2.0.0\n",
      "  Downloading azure_nspkg-3.0.2-py3-none-any.whl (1.5 kB)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (4.1.1)\n",
      "Requirement already satisfied: cryptography in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-cosmosdb-table~=1.0->azure->-r requirements.txt (line 1)) (3.4.8)\n",
      "Collecting azure-cosmosdb-nspkg>=2.0.0\n",
      "  Downloading azure_cosmosdb_nspkg-2.0.2-py2.py3-none-any.whl (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-cosmosdb-table~=1.0->azure->-r requirements.txt (line 1)) (2.8.2)\n",
      "Collecting adal>=0.4.2\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: cffi in c:\\users\\marci\\anaconda3\\lib\\site-packages (from azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from adal>=0.4.2->azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (2.1.0)\n",
      "Collecting azure-mgmt-compute~=4.0\n",
      "  Downloading azure_mgmt_compute-4.6.2-py2.py3-none-any.whl (3.0 MB)\n",
      "Collecting azure-mgmt-keyvault~=1.0\n",
      "  Downloading azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-mgmt-batch~=5.0\n",
      "  Downloading azure_mgmt_batch-5.0.1-py2.py3-none-any.whl (87 kB)\n",
      "Collecting azure-mgmt-advisor~=1.0\n",
      "  Downloading azure_mgmt_advisor-1.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting azure-mgmt-devtestlabs~=2.2\n",
      "  Downloading azure_mgmt_devtestlabs-2.2.0-py2.py3-none-any.whl (194 kB)\n",
      "Collecting azure-mgmt-logic~=3.0\n",
      "  Downloading azure_mgmt_logic-3.0.0-py2.py3-none-any.whl (303 kB)\n",
      "Collecting azure-mgmt-redis~=5.0\n",
      "  Downloading azure_mgmt_redis-5.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting azure-mgmt-rdbms~=1.2\n",
      "  Downloading azure_mgmt_rdbms-1.9.0-py2.py3-none-any.whl (259 kB)\n",
      "Collecting azure-mgmt-policyinsights~=0.1.0\n",
      "  Downloading azure_mgmt_policyinsights-0.1.0-py2.py3-none-any.whl (44 kB)\n",
      "Collecting azure-mgmt-storage~=2.0\n",
      "  Downloading azure_mgmt_storage-2.0.0-py2.py3-none-any.whl (558 kB)\n",
      "Collecting azure-mgmt-datalake-analytics~=0.6.0\n",
      "  Downloading azure_mgmt_datalake_analytics-0.6.0-py2.py3-none-any.whl (288 kB)\n",
      "Collecting azure-mgmt-datafactory~=0.6.0\n",
      "  Downloading azure_mgmt_datafactory-0.6.0-py2.py3-none-any.whl (418 kB)\n",
      "Collecting azure-mgmt-datamigration~=1.0\n",
      "  Downloading azure_mgmt_datamigration-1.0.0-py2.py3-none-any.whl (185 kB)\n",
      "Collecting azure-mgmt-recoveryservices~=0.3.0\n",
      "  Downloading azure_mgmt_recoveryservices-0.3.0-py2.py3-none-any.whl (70 kB)\n",
      "Collecting azure-mgmt-devspaces~=0.1.0\n",
      "  Downloading azure_mgmt_devspaces-0.1.0-py2.py3-none-any.whl (33 kB)\n",
      "Collecting azure-mgmt-marketplaceordering~=0.1.0\n",
      "  Downloading azure_mgmt_marketplaceordering-0.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting azure-mgmt-powerbiembedded~=2.0\n",
      "  Downloading azure_mgmt_powerbiembedded-2.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-mgmt-cognitiveservices~=3.0\n",
      "  Downloading azure_mgmt_cognitiveservices-3.0.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azure-mgmt-subscription~=0.2.0\n",
      "  Downloading azure_mgmt_subscription-0.2.0-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-mgmt-scheduler~=2.0\n",
      "  Downloading azure_mgmt_scheduler-2.0.0-py2.py3-none-any.whl (67 kB)\n",
      "Collecting azure-mgmt-servicefabric~=0.2.0\n",
      "  Downloading azure_mgmt_servicefabric-0.2.0-py2.py3-none-any.whl (142 kB)\n",
      "Collecting azure-mgmt-eventgrid~=1.0\n",
      "  Downloading azure_mgmt_eventgrid-1.0.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting azure-mgmt-msi~=0.2.0\n",
      "  Downloading azure_mgmt_msi-0.2.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting azure-mgmt-recoveryservicesbackup~=0.3.0\n",
      "  Downloading azure_mgmt_recoveryservicesbackup-0.3.0-py2.py3-none-any.whl (568 kB)\n",
      "Collecting azure-mgmt-managementpartner~=0.1.0\n",
      "  Downloading azure_mgmt_managementpartner-0.1.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting azure-mgmt-containerservice~=4.2\n",
      "  Downloading azure_mgmt_containerservice-4.4.0-py2.py3-none-any.whl (206 kB)\n",
      "Collecting azure-mgmt-hanaonazure~=0.1.1\n",
      "  Downloading azure_mgmt_hanaonazure-0.1.1-py2.py3-none-any.whl (20 kB)\n",
      "Collecting azure-mgmt-search~=2.0\n",
      "  Downloading azure_mgmt_search-2.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting azure-mgmt-signalr~=0.1.0\n",
      "  Downloading azure_mgmt_signalr-0.1.1-py2.py3-none-any.whl (49 kB)\n",
      "Collecting azure-mgmt-servicebus~=0.5.1\n",
      "  Downloading azure_mgmt_servicebus-0.5.3-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azure-mgmt-iothubprovisioningservices~=0.2.0\n",
      "  Downloading azure_mgmt_iothubprovisioningservices-0.2.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting azure-mgmt-containerinstance~=1.0\n",
      "  Downloading azure_mgmt_containerinstance-1.5.0-py2.py3-none-any.whl (96 kB)\n",
      "Collecting azure-mgmt-commerce~=1.0\n",
      "  Downloading azure_mgmt_commerce-1.0.1-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azure-mgmt-sql~=0.9.1\n",
      "  Downloading azure_mgmt_sql-0.9.1-py2.py3-none-any.whl (485 kB)\n",
      "Collecting azure-mgmt-loganalytics~=0.2.0\n",
      "  Downloading azure_mgmt_loganalytics-0.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting azure-mgmt-cosmosdb~=0.4.1\n",
      "  Downloading azure_mgmt_cosmosdb-0.4.1-py2.py3-none-any.whl (100 kB)\n",
      "Collecting azure-mgmt-datalake-store~=0.5.0\n",
      "  Downloading azure_mgmt_datalake_store-0.5.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting azure-mgmt-eventhub~=2.1\n",
      "  Downloading azure_mgmt_eventhub-2.6.0-py2.py3-none-any.whl (189 kB)\n",
      "Collecting azure-mgmt-resource~=2.0\n",
      "  Downloading azure_mgmt_resource-2.2.0-py2.py3-none-any.whl (780 kB)\n",
      "Collecting azure-mgmt-containerregistry~=2.1\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azure-mgmt-relay~=0.1.0\n",
      "  Downloading azure_mgmt_relay-0.1.0-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-mgmt-batchai~=2.0\n",
      "  Downloading azure_mgmt_batchai-2.0.0-py2.py3-none-any.whl (174 kB)\n",
      "Collecting azure-mgmt-notificationhubs~=2.0\n",
      "  Downloading azure_mgmt_notificationhubs-2.1.0-py2.py3-none-any.whl (76 kB)\n",
      "Collecting azure-mgmt-machinelearningcompute~=0.4.1\n",
      "  Downloading azure_mgmt_machinelearningcompute-0.4.1-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-mgmt-monitor~=0.5.2\n",
      "  Downloading azure_mgmt_monitor-0.5.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting azure-mgmt-iotcentral~=0.1.0\n",
      "  Downloading azure_mgmt_iotcentral-0.1.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting azure-mgmt-consumption~=2.0\n",
      "  Downloading azure_mgmt_consumption-2.0.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting azure-mgmt-trafficmanager~=0.50.0\n",
      "  Downloading azure_mgmt_trafficmanager-0.50.0-py2.py3-none-any.whl (52 kB)\n",
      "Collecting azure-mgmt-cdn~=3.0\n",
      "  Downloading azure_mgmt_cdn-3.1.0-py2.py3-none-any.whl (119 kB)\n",
      "Collecting azure-mgmt-dns~=2.0\n",
      "  Downloading azure_mgmt_dns-2.1.0-py2.py3-none-any.whl (134 kB)\n",
      "Collecting azure-mgmt-reservations~=0.2.1\n",
      "  Downloading azure_mgmt_reservations-0.2.1-py2.py3-none-any.whl (50 kB)\n",
      "Collecting azure-mgmt-billing~=0.2.0\n",
      "  Downloading azure_mgmt_billing-0.2.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azure-mgmt-managementgroups~=0.1.0\n",
      "  Downloading azure_mgmt_managementgroups-0.1.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting azure-mgmt-media~=1.0.0rc2\n",
      "  Downloading azure_mgmt_media-1.0.1-py2.py3-none-any.whl (335 kB)\n",
      "Collecting azure-mgmt-applicationinsights~=0.1.1\n",
      "  Downloading azure_mgmt_applicationinsights-0.1.1-py2.py3-none-any.whl (42 kB)\n",
      "Collecting azure-mgmt-authorization~=0.50.0\n",
      "  Downloading azure_mgmt_authorization-0.50.0-py2.py3-none-any.whl (81 kB)\n",
      "Collecting azure-mgmt-iothub~=0.5.0\n",
      "  Downloading azure_mgmt_iothub-0.5.0-py2.py3-none-any.whl (102 kB)\n",
      "Collecting azure-mgmt-web~=0.35.0\n",
      "  Downloading azure_mgmt_web-0.35.0-py2.py3-none-any.whl (358 kB)\n",
      "Collecting azure-mgmt-network~=2.0\n",
      "  Downloading azure_mgmt_network-2.7.0-py2.py3-none-any.whl (11.4 MB)\n",
      "Collecting azure-mgmt-maps~=0.1.0\n",
      "  Downloading azure_mgmt_maps-0.1.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting azure-mgmt-nspkg>=2.0.0\n",
      "  Downloading azure_mgmt_nspkg-3.0.2-py3-none-any.whl (1.6 kB)\n",
      "Collecting azure-mgmt-datalake-nspkg>=2.0.0\n",
      "  Downloading azure_mgmt_datalake_nspkg-3.0.1-py3-none-any.whl (1.7 kB)\n",
      "Collecting azure-storage-common~=1.4\n",
      "  Downloading azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\marci\\anaconda3\\lib\\site-packages (from cffi->azure-datalake-store~=0.0.18->azure->-r requirements.txt (line 1)) (2.21)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-applicationinsights~=0.1.0->azure->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marci\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos->-r requirements.txt (line 2)) (1.26.9)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, isodate, azure-nspkg, azure-core, msrest, azure-mgmt-nspkg, adal, msrestazure, azure-mgmt-datalake-nspkg, azure-common, azure-storage-common, azure-mgmt-web, azure-mgmt-trafficmanager, azure-mgmt-subscription, azure-mgmt-storage, azure-mgmt-sql, azure-mgmt-signalr, azure-mgmt-servicefabric, azure-mgmt-servicebus, azure-mgmt-search, azure-mgmt-scheduler, azure-mgmt-resource, azure-mgmt-reservations, azure-mgmt-relay, azure-mgmt-redis, azure-mgmt-recoveryservicesbackup, azure-mgmt-recoveryservices, azure-mgmt-rdbms, azure-mgmt-powerbiembedded, azure-mgmt-policyinsights, azure-mgmt-notificationhubs, azure-mgmt-network, azure-mgmt-msi, azure-mgmt-monitor, azure-mgmt-media, azure-mgmt-marketplaceordering, azure-mgmt-maps, azure-mgmt-managementpartner, azure-mgmt-managementgroups, azure-mgmt-machinelearningcompute, azure-mgmt-logic, azure-mgmt-loganalytics, azure-mgmt-keyvault, azure-mgmt-iothubprovisioningservices, azure-mgmt-iothub, azure-mgmt-iotcentral, azure-mgmt-hanaonazure, azure-mgmt-eventhub, azure-mgmt-eventgrid, azure-mgmt-dns, azure-mgmt-devtestlabs, azure-mgmt-devspaces, azure-mgmt-datamigration, azure-mgmt-datalake-store, azure-mgmt-datalake-analytics, azure-mgmt-datafactory, azure-mgmt-cosmosdb, azure-mgmt-containerservice, azure-mgmt-containerregistry, azure-mgmt-containerinstance, azure-mgmt-consumption, azure-mgmt-compute, azure-mgmt-commerce, azure-mgmt-cognitiveservices, azure-mgmt-cdn, azure-mgmt-billing, azure-mgmt-batchai, azure-mgmt-batch, azure-mgmt-authorization, azure-mgmt-applicationinsights, azure-mgmt-advisor, azure-cosmosdb-nspkg, azure-storage-queue, azure-storage-file, azure-storage-blob, azure-servicemanagement-legacy, azure-servicefabric, azure-servicebus, azure-mgmt, azure-loganalytics, azure-keyvault, azure-graphrbac, azure-eventgrid, azure-datalake-store, azure-cosmosdb-table, azure-batch, azure-applicationinsights, azure-cosmos, azure\n",
      "Successfully installed adal-1.2.7 azure-4.0.0 azure-applicationinsights-0.1.1 azure-batch-4.1.3 azure-common-1.1.28 azure-core-1.24.2 azure-cosmos-4.3.0 azure-cosmosdb-nspkg-2.0.2 azure-cosmosdb-table-1.0.6 azure-datalake-store-0.0.52 azure-eventgrid-1.3.0 azure-graphrbac-0.40.0 azure-keyvault-1.1.0 azure-loganalytics-0.1.1 azure-mgmt-4.0.0 azure-mgmt-advisor-1.0.1 azure-mgmt-applicationinsights-0.1.1 azure-mgmt-authorization-0.50.0 azure-mgmt-batch-5.0.1 azure-mgmt-batchai-2.0.0 azure-mgmt-billing-0.2.0 azure-mgmt-cdn-3.1.0 azure-mgmt-cognitiveservices-3.0.0 azure-mgmt-commerce-1.0.1 azure-mgmt-compute-4.6.2 azure-mgmt-consumption-2.0.0 azure-mgmt-containerinstance-1.5.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-containerservice-4.4.0 azure-mgmt-cosmosdb-0.4.1 azure-mgmt-datafactory-0.6.0 azure-mgmt-datalake-analytics-0.6.0 azure-mgmt-datalake-nspkg-3.0.1 azure-mgmt-datalake-store-0.5.0 azure-mgmt-datamigration-1.0.0 azure-mgmt-devspaces-0.1.0 azure-mgmt-devtestlabs-2.2.0 azure-mgmt-dns-2.1.0 azure-mgmt-eventgrid-1.0.0 azure-mgmt-eventhub-2.6.0 azure-mgmt-hanaonazure-0.1.1 azure-mgmt-iotcentral-0.1.0 azure-mgmt-iothub-0.5.0 azure-mgmt-iothubprovisioningservices-0.2.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-loganalytics-0.2.0 azure-mgmt-logic-3.0.0 azure-mgmt-machinelearningcompute-0.4.1 azure-mgmt-managementgroups-0.1.0 azure-mgmt-managementpartner-0.1.1 azure-mgmt-maps-0.1.0 azure-mgmt-marketplaceordering-0.1.0 azure-mgmt-media-1.0.1 azure-mgmt-monitor-0.5.2 azure-mgmt-msi-0.2.0 azure-mgmt-network-2.7.0 azure-mgmt-notificationhubs-2.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-policyinsights-0.1.0 azure-mgmt-powerbiembedded-2.0.0 azure-mgmt-rdbms-1.9.0 azure-mgmt-recoveryservices-0.3.0 azure-mgmt-recoveryservicesbackup-0.3.0 azure-mgmt-redis-5.0.0 azure-mgmt-relay-0.1.0 azure-mgmt-reservations-0.2.1 azure-mgmt-resource-2.2.0 azure-mgmt-scheduler-2.0.0 azure-mgmt-search-2.1.0 azure-mgmt-servicebus-0.5.3 azure-mgmt-servicefabric-0.2.0 azure-mgmt-signalr-0.1.1 azure-mgmt-sql-0.9.1 azure-mgmt-storage-2.0.0 azure-mgmt-subscription-0.2.0 azure-mgmt-trafficmanager-0.50.0 azure-mgmt-web-0.35.0 azure-nspkg-3.0.2 azure-servicebus-0.21.1 azure-servicefabric-6.3.0.0 azure-servicemanagement-legacy-0.20.7 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 isodate-0.6.1 msrest-0.7.1 msrestazure-0.6.4 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\Users\\marci\\anaconda3\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\marci\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rwo0kq2b\\\\azure_775b6b7bf5fc4708bc4b4e5742e97080\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\marci\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rwo0kq2b\\\\azure_775b6b7bf5fc4708bc4b4e5742e97080\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\marci\\AppData\\Local\\Temp\\pip-pip-egg-info-n5z_lqxj'\n",
      "         cwd: C:\\Users\\marci\\AppData\\Local\\Temp\\pip-install-rwo0kq2b\\azure_775b6b7bf5fc4708bc4b4e5742e97080\\\n",
      "    Complete output (24 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\marci\\AppData\\Local\\Temp\\pip-install-rwo0kq2b\\azure_775b6b7bf5fc4708bc4b4e5742e97080\\setup.py\", line 60, in <module>\n",
      "        raise RuntimeError(message)\n",
      "    RuntimeError:\n",
      "    \n",
      "    Starting with v5.0.0, the 'azure' meta-package is deprecated and cannot be installed anymore.\n",
      "    Please install the service specific packages prefixed by `azure` needed for your application.\n",
      "    \n",
      "    The complete list of available packages can be found at:\n",
      "    https://aka.ms/azsdk/python/all\n",
      "    \n",
      "    Here's a non-exhaustive list of common packages:\n",
      "    \n",
      "    -  azure-mgmt-compute (https://pypi.python.org/pypi/azure-mgmt-compute) : Management of Virtual Machines, etc.\n",
      "    -  azure-mgmt-storage (https://pypi.python.org/pypi/azure-mgmt-storage) : Management of storage accounts.\n",
      "    -  azure-mgmt-resource (https://pypi.python.org/pypi/azure-mgmt-resource) : Generic package about Azure Resource Management (ARM)\n",
      "    -  azure-keyvault-secrets (https://pypi.python.org/pypi/azure-keyvault-secrets) : Access to secrets in Key Vault\n",
      "    -  azure-storage-blob (https://pypi.python.org/pypi/azure-storage-blob) : Access to blobs in storage accounts\n",
      "    \n",
      "    A more comprehensive discussion of the rationale for this decision can be found in the following issue:\n",
      "    https://github.com/Azure/azure-sdk-for-python/issues/10646\n",
      "    \n",
      "    \n",
      "    ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/e8/48/ef73d5e71ecb84cacaeaf533f519be81825ad6198acc41bd821f440e7f7c/azure-5.0.0.zip#sha256=f56d22acaba0ce74b821fd3d012d18854f9d0b3662d5a3a9240b1bd587c96b23 (from https://pypi.org/simple/azure/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the [reference page for the CosmosClient method](https://docs.microsoft.com/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#createdatabase-database--options-none-), other than the URL and the authentication you can supply a [connection policy](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.documents.connectionpolicy?view=azure-python) and the consistency level to use.\n",
    "\n",
    "The connection policy is especially interesting, since it allows defining attributes such as a list of preferred locations to use (typically the closest geographically to the application), disable SSL verification or retry options, amongst others. Refer to the [reference documentation](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.documents.connectionpolicy?view=azure-python) for more information on the connection policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'host': os.environ.get('ACCOUNT_HOST', 'https://a53e3541-0ee0-4-231-b9ee.documents.azure.com:443/'),\n",
    "    'master_key': os.environ.get('ACCOUNT_KEY', 'Z2LRcLqgZLEgN6OlHJAxAlRhbbOTiwE6jMyL6klscppbvOOvqH65o7vzSlX77TguCSgTCxx5IRzRNEUvPXOLug=='),\n",
    "    'database_id': os.environ.get('COSMOS_DATABASE', 'ToDoList'),\n",
    "    'container_id': os.environ.get('COSMOS_CONTAINER', 'Items'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = settings['host']\n",
    "MASTER_KEY = settings['master_key']\n",
    "DATABASE_ID = settings['database_id']\n",
    "CONTAINER_ID = settings['container_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cosmos.cosmos_client as cosmos_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cosmos_client.CosmosClient(HOST, {'masterKey': MASTER_KEY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Incorrect padding",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9b44fe90c4e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosmos_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCosmosClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_connection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcosmosdb_endpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'masterKey'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maccount_key\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\cosmos_client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url_connection, auth, connection_policy, consistency_level)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_routing_map_provider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrouting_map_provider\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SmartRoutingMapProvider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mdatabase_account\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_global_endpoint_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_GetDatabaseAccount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_global_endpoint_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase_account\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\global_endpoint_manager.py\u001b[0m in \u001b[0;36m_GetDatabaseAccount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mdatabase_account\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_GetDatabaseAccountStub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefaultEndpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdatabase_account\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# If for any reason(non-globaldb related), we are not able to get the database account from the above call to GetDatabaseAccount,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\global_endpoint_manager.py\u001b[0m in \u001b[0;36m_GetDatabaseAccountStub\u001b[1;34m(self, endpoint)\u001b[0m\n\u001b[0;32m    128\u001b[0m            \u001b[0mwhich\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmocking\u001b[0m \u001b[0mpurposes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetDatabaseAccount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\cosmos_client.py\u001b[0m in \u001b[0;36mGetDatabaseAccount\u001b[1;34m(self, url_connection)\u001b[0m\n\u001b[0;32m   2390\u001b[0m                                   \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m                                   \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2392\u001b[1;33m                                   {})\n\u001b[0m\u001b[0;32m   2393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RequestObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'databaseaccount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_OperationType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\base.py\u001b[0m in \u001b[0;36mGetHeaders\u001b[1;34m(cosmos_client, default_headers, verb, path, resource_id, resource_type, options, partition_key_range_id)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                         \u001b[0mIsNameBased\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                                         \u001b[0mresource_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                                         headers)\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;31m# urllib.quote throws when the input parameter is None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mauthorization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\auth.py\u001b[0m in \u001b[0;36mGetAuthorizationHeader\u001b[1;34m(cosmos_client, verb, path, resource_id_or_fullname, is_name_based, resource_type, headers)\u001b[0m\n\u001b[0;32m     59\u001b[0m                                                     \u001b[0mresource_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                     \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                     cosmos_client.master_key)\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcosmos_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         return __GetAuthorizationTokenUsingResourceTokens(\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\site-packages\\azure\\cosmos\\auth.py\u001b[0m in \u001b[0;36m__GetAuthorizationTokenUsingMasterKey\u001b[1;34m(verb, resource_id_or_fullname, resource_type, headers, master_key)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# decodes the master key which is encoded in base64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaster_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Skipping lower casing of resource_id_or_fullname since it may now contain \"ID\" of the resource as part of the fullname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marci\\.conda\\envs\\azure\\lib\\base64.py\u001b[0m in \u001b[0;36mb64decode\u001b[1;34m(s, altchars, validate)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'^[A-Za-z0-9+/]*={0,2}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Non-base64 digit found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma2b_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: Incorrect padding"
     ]
    }
   ],
   "source": [
    "client = cosmos_client.CosmosClient(url_connection=cosmosdb_endpoint, auth={'masterKey': account_key})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database and Collection\n",
    "\n",
    "With an initialized client we can now create a database and a collection. Note that you can allocate a performance to the database or to the collection. In this example we will allocate the minimum allowed performance (400 RU/s) to the collection.\n",
    "\n",
    "See the reference guide for the [createDatabase method](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#createdatabase-database--options-none-) and for the [createContainer method](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#createcontainer--link--collection--options-none-).\n",
    "\n",
    "Note how when creating a container (called \"collection\" for document-based schemas) you specify some attributes as part as the collection definition (such as the partition key or the indexing), and others as options (such as the throughput).\n",
    "\n",
    "Note that in this example we use the property \"source\" as partition key. This is probably not an ideal partition scheme as we will see during the rest of the notebook, but please do not change this, otherwise some exercises in the notebook will not work as designed. You can find more information about partitions in Cosmos DB [here](https://docs.microsoft.com/azure/cosmos-db/partitioning-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_definition = { 'id': db_name }\n",
    "created_db = client.CreateDatabase(database_definition)\n",
    "db_link=created_db['_self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection customers has been created\n"
     ]
    }
   ],
   "source": [
    "# Before creating the collection, this code makes sure it does not exist before\n",
    "# Otherwise it gives out an error, that you could grab in a try/catch block as well\n",
    "coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "coll = list(client.QueryContainers(db_link, coll_query))\n",
    "if coll:\n",
    "    print(\"Collection\", coll_name, \"already exists\")\n",
    "else:\n",
    "    collection_definition = {\n",
    "        'id': coll_name, \n",
    "        'indexingPolicy': {'indexingMode': 'consistent'},\n",
    "        'partitionKey': {\n",
    "            'paths': [\n",
    "              '/source'\n",
    "            ],\n",
    "            'kind': 'Hash'\n",
    "        }\n",
    "    }\n",
    "    collection_options = { 'offerThroughput': 400 }\n",
    "    created_collection = client.CreateContainer(created_db['_self'], collection_definition, collection_options)\n",
    "    print(\"Collection\", coll_name, \"has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an existing database or collection\n",
    "\n",
    "If you are working with an existing database or collection, you just need to retrieve them. The retrieved object will have an s_id field that you can use to verify whether the database and collections where found or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ecommerce found\n",
      "Collection customers found:\n",
      " - Indexing policy - Mode: consistent\n",
      " - Indexing policy - Mode: True\n",
      " - Conflict resolution policy mode: LastWriterWins\n"
     ]
    }
   ],
   "source": [
    "# Get the DB link\n",
    "db_query = \"select * from r where r.id = '{0}'\".format(db_name)\n",
    "db = list(client.QueryDatabases(db_query))\n",
    "if db:\n",
    "    db_link = db[0]['_self']\n",
    "    print(\"Database\", db_name, \"found\")\n",
    "    # Uncomment the next line to see the full object\n",
    "    # print(db[0])\n",
    "\n",
    "    # If the database has been found, try to find the collection\n",
    "    coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "    coll = list(client.QueryContainers(db_link, coll_query))\n",
    "    if coll:\n",
    "        coll_link = coll[0]['_self']\n",
    "        print(\"Collection\", coll_name, \"found:\")\n",
    "        print(\" - Indexing policy - Mode:\", coll[0]['indexingPolicy']['indexingMode'])\n",
    "        print(\" - Indexing policy - Mode:\", coll[0]['indexingPolicy']['automatic'])\n",
    "        print(\" - Conflict resolution policy mode:\", coll[0]['conflictResolutionPolicy']['mode'])\n",
    "        # Uncomment the next line to see the full object\n",
    "        # print(coll[0])\n",
    "    else:\n",
    "        print(\"Collection\", coll_name, \"not found :(\")\n",
    "else:\n",
    "    print(\"Database\", db_name, \"not found :(\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to the QueryContainers method, you can craft manually a collection link with the database and collection names, and use the method ReadCollection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_link='dbs/{0}/colls/{1}/'.format(db_name, coll_name)\n",
    "print(\"Collection link:\", coll_link)\n",
    "collection = client.ReadContainer(coll_link)\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting an existing database or collection\n",
    "\n",
    "If you want to play with the different options to create a collection, you can modify most of its attributes, with the notable exception of the partition key. If you need to try the commands above with different options you might have to delete the collection first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete only a specific collection\n",
    "coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "coll = list(client.QueryContainers(db_link, coll_query))\n",
    "if coll:\n",
    "    coll_link = coll[0]['_self']\n",
    "    client.DeleteContainer(coll_link)\n",
    "    print(\"Collection\", coll_name, \"has been deleted\")\n",
    "else:\n",
    "    print(\"Collection\", coll_name, \"could not be found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the DB exists, delete it (including any collections)\n",
    "db_query = \"select * from r where r.id = '{0}'\".format(db_name)\n",
    "db = list(client.QueryDatabases(db_query))\n",
    "if db:\n",
    "    db_link = db[0]['_self']\n",
    "    client.DeleteDatabase(db_link)\n",
    "    print(\"Database\", db_name, \"and all its collections have been deleted\")\n",
    "else:\n",
    "    print(\"Database\", db_name, \"could not be found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the RUs of an existing collection\n",
    "\n",
    "You might want to update the performance (throughput) of your collection under certain circumstances, for example occasionally to perform a performance-intensive operation such as a data import or export, or just because you need more performance on your database on a consistent basis.\n",
    "\n",
    "To read the current throughput of an existing collection you can use the QueryOffers method, and update it with the ReplaceOffers method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "coll = list(client.QueryContainers(db_link, coll_query))\n",
    "if coll:\n",
    "    # We found our collection, get the link and find the offers\n",
    "    coll_link = coll[0]['_self']\n",
    "    offer = list(client.QueryOffers('SELECT * FROM c WHERE c.resource = \\'{0}\\''.format(coll_link)))[0]\n",
    "    print(\"Collection\", coll_name, \"found provisioned with\", str(offer['content']['offerThroughput']), \"RU/s\")\n",
    "else:\n",
    "    print(\"Collection\", coll_name, \"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_offer = offer\n",
    "new_offer['content']['offerThroughput'] += 50\n",
    "throughput = new_offer['content']['offerThroughput']\n",
    "if (throughput >= 400) and (throughput <= 100000) and ((throughput % 100) == 0): \n",
    "    offer = client.ReplaceOffer(offer['_self'], new_offer)\n",
    "else:\n",
    "    print(throughput, \"is not a valid throughput for Cosmos DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create documents\n",
    "\n",
    "You can use the Python SDK to create new documents in our collection. For this we will use some sample documents, that are used as well in the [EDX course for Cosmos DB](https://courses.edx.org/courses/course-v1:Microsoft+DAT237x+2T2017/course/). In that course these documents are used to illustrate the .NET API, we will use them here for the Python SDK.\n",
    "\n",
    "The function insert_item supports a \"pretrigger\" argument, please ignore it for the time being (we will come back to it later in this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need these throughout the notebook\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single add\n",
    "def insert_item(client, coll_link, item, pretrigger=None):\n",
    "    options={}\n",
    "    if pretrigger:\n",
    "        options['preTriggerInclude'] = pretrigger\n",
    "    client.CreateItem(coll_link, item, options)\n",
    "\n",
    "# Add all documents in a specific folder\n",
    "def insert_items_batch(client, coll_link, data_dir):\n",
    "    jsonpath = os.path.join(os.getcwd(), data_dir)\n",
    "    counter=0\n",
    "    for file in os.listdir(jsonpath):\n",
    "        if file[-5:] == \".json\":\n",
    "            #print(\"Found json file\", file)\n",
    "            f=open(os.path.join(jsonpath, file), 'r')\n",
    "            item_json = f.read()\n",
    "            item = json.loads(item_json)\n",
    "            insert_item(client, coll_link, item)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(\"Non-JSON file found:\", file)\n",
    "    print(counter, \"documents added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 documents added\n"
     ]
    }
   ],
   "source": [
    "insert_items_batch(client, coll_link, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying documents\n",
    "\n",
    "Now that we have some data in the collection, we can start running some queries. Let us start with something simple. As you can see, the send_query function supports defining query options, we will see those in a minute. See the reference documentation for the [QueryItems](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#queryitems-database-or-container-link--query--options-none--partition-key-none-) method for more information.\n",
    "\n",
    "In the example below, for output clarity the send_query function has an optional toggle that can be used to hide the actual results, and print only the number of matching documents, as well as the RU/s consumed by this particular query. Note how the consumed RU's are obtained by looking at a specific field of the client object, that contains the consumed RU's for the last operation.\n",
    "\n",
    "You can find more examples of queries for Azure Cosmos DB [here](https://docs.microsoft.com/azure/cosmos-db/how-to-sql-query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function that we will use to send a query to a collection\n",
    "def send_query(client, coll_link, query, options=None, show_results=True):\n",
    "    docs = list(client.QueryItems(coll_link, query, options))\n",
    "    for doc in docs:\n",
    "        if show_results:\n",
    "            print(json.dumps(doc, indent=4, sort_keys=True))\n",
    "    print(len(docs), 'items found,', client.last_response_headers['x-ms-request-charge'], 'RU/s consumed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 items found, 2.93 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "# Query with partition ID\n",
    "customer_id='09d2bb28e9c54bc581492d542789f2ad'\n",
    "source='other'\n",
    "query = 'SELECT * FROM customers WHERE customers.source=\\'{0}\\' AND customers.id=\\'{1}\\''.format(source, customer_id)\n",
    "send_query(client, coll_link, query, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you leave out the source in the query, as the example below, Cosmos DB is forced to look into every partition. Hence, if you do not specify in the options that this is to be a cross-partition query, you will get an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 items found, 2.83 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "# Query without partition ID\n",
    "customer_id='09d2bb28e9c54bc581492d542789f2ad'\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "query = 'SELECT * FROM customers WHERE customers.id=\\'{0}\\''.format(customer_id)\n",
    "send_query(client, coll_link, query, options=options, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have seen in the code for send_query, you can send some options along with the query, that will modify the way in which the query is executed. For example, we can enable cross-partition queries (to be able to select all records) and set the maximum item count to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 items found, 2.25 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "# Simple query with options\n",
    "query = 'SELECT * FROM customers'\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "options['maxItemCount'] = 2\n",
    "send_query(client, coll_link, query, options, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex queries are supported using the SQL dialect of Cosmos DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 items found, 2.98 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "# Query showing projection and filtering\n",
    "query='''SELECT {\n",
    "     \"full-name\": customers.name,\n",
    "     \"contact-details\": {\n",
    "        \"phone\": customers.phone,\n",
    "        \"address\": customers.address\n",
    "    },\n",
    "     \"employment\": {\n",
    "        \"employer\": customers.company,\n",
    "        \"work-email\": customers.email\n",
    "     }\n",
    "} AS person\n",
    "FROM customers\n",
    "WHERE customers.source = \"retail-location\"'''\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggers\n",
    "\n",
    "Triggers are activites that can be executed before (\"Pre\" triggers) or after (\"Post\" triggers) data being written or updated in Cosmos DB. Triggers are written in JavaScript, which makes working with JSON very easy. In this repository we have a trigger that adds a 'department' property to a document before adding it to the collection, in case that property did not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function validateDepartmentExists() {\n",
      "    var context = getContext();\n",
      "    var request = context.getRequest();\n",
      "    var newDocument = request.getBody();\n",
      "\n",
      "    if (!newDocument.department) {\n",
      "        newDocument[\"department\"] = \"General\"\n",
      "    }\n",
      "\n",
      "    request.setBody(newDocument);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trigger_filename = os.path.join(os.getcwd(), 'triggers', 'validateDepartmentExists.js')\n",
    "f=open(trigger_filename, 'r')\n",
    "trigger_code = f.read()\n",
    "print(trigger_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_etag\": \"\\\"21016a1d-0000-0200-0000-62cb722a0000\\\"\",\n",
      "    \"_rid\": \"eGolAPPsVeoBAAAAAAAAcA==\",\n",
      "    \"_self\": \"dbs/eGolAA==/colls/eGolAPPsVeo=/triggers/eGolAPPsVeoBAAAAAAAAcA==/\",\n",
      "    \"_ts\": 1657500202,\n",
      "    \"body\": \"function validateDepartmentExists() {\\n    var context = getContext();\\n    var request = context.getRequest();\\n    var newDocument = request.getBody();\\n\\n    if (!newDocument.department) {\\n        newDocument[\\\"department\\\"] = \\\"General\\\"\\n    }\\n\\n    request.setBody(newDocument);\\n}\",\n",
      "    \"id\": \"validateDepartmentExists\",\n",
      "    \"triggerOperation\": \"all\",\n",
      "    \"triggerType\": \"pre\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import azure.cosmos.documents as documents\n",
    "\n",
    "# Create new trigger from file\n",
    "def create_trigger(client, coll_link, filename):\n",
    "    with open(filename) as file:\n",
    "        file_contents = file.read()\n",
    "    trigger_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    trigger_definition = {\n",
    "        'id': trigger_name,\n",
    "        'serverScript': file_contents,\n",
    "        'triggerType': documents.TriggerType.Pre,\n",
    "        'triggerOperation': documents.TriggerOperation.All\n",
    "    }\n",
    "    trigger = client.CreateTrigger(coll_link, trigger_definition)\n",
    "\n",
    "# List existing defined triggers in the collection\n",
    "def query_triggers(client, coll_link):\n",
    "    trigger_query = 'select * from r'\n",
    "    triggers = list(client.QueryTriggers(coll_link, trigger_query))\n",
    "    for trigger in triggers:\n",
    "        print(json.dumps(trigger, indent=4, sort_keys=True))\n",
    "\n",
    "    \n",
    "trigger_filename = os.path.join(os.getcwd(), 'triggers', 'validateDepartmentExists.js')\n",
    "create_trigger(client, coll_link, trigger_filename)\n",
    "query_triggers(client, coll_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add a new document without the 'department' property, and verify that the property was added by the Trigger. For that we will use a helper function that generates a customer with a random ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "def get_random_item():\n",
    "    random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=16))\n",
    "    itemToCreate = {\n",
    "        'firstName': 'Sample',\n",
    "        'lastName': 'Person',\n",
    "        'id': random_id,\n",
    "        'source': 'random'\n",
    "    }\n",
    "    return itemToCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will send an item without the 'department' property:\n",
      "{'firstName': 'Sample', 'lastName': 'Person', 'id': 'p84rg7evw3qefjvh', 'source': 'random'}\n",
      "And now the item actually created should have the 'department' property, added by the trigger:\n",
      "{\n",
      "    \"_attachments\": \"attachments/\",\n",
      "    \"_etag\": \"\\\"2101751d-0000-0200-0000-62cb72320000\\\"\",\n",
      "    \"_rid\": \"eGolAPPsVeozAAAAAAAAAA==\",\n",
      "    \"_self\": \"dbs/eGolAA==/colls/eGolAPPsVeo=/docs/eGolAPPsVeozAAAAAAAAAA==/\",\n",
      "    \"_ts\": 1657500210,\n",
      "    \"department\": \"General\",\n",
      "    \"firstName\": \"Sample\",\n",
      "    \"id\": \"p84rg7evw3qefjvh\",\n",
      "    \"lastName\": \"Person\",\n",
      "    \"source\": \"random\"\n",
      "}\n",
      "1 items found, 2.82 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "random_item = get_random_item()\n",
    "print('We will send an item without the \\'department\\' property:')\n",
    "print(random_item)\n",
    "# Note that we do specify the ID of the Pre trigger to execute\n",
    "insert_item(client, coll_link, random_item, pretrigger='validateDepartmentExists')\n",
    "print(\"And now the item actually created should have the \\'department\\' property, added by the trigger:\")\n",
    "query = 'SELECT * FROM customers WHERE customers.id = \\'{0}\\''.format(random_item['id'])\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions (UDF)\n",
    "\n",
    "You can define your own functions that can be used in queries. In this section we are going to create a user-defined function (UDF) that converts from US dollars to euros. The function is in the \"udf\" directory of this repository. First we will add the function to the collection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'convertToEuro',\n",
       " 'body': 'function convertToEuro(currency_in_usd_text) {\\n    var currency_in_usd_number = Number(currency_in_usd_text.replace(/[^0-9.-]+/g,\"\"));\\n    currency_in_eur_number = currency_in_usd_number * 0.8898;\\n    currency_in_eur_text = currency_in_eur_number.toLocaleString(\\'en-US\\', { maximumFractionDigits: 2 })\\n    return \"EUR\".concat(currency_in_eur_text)\\n}',\n",
       " '_rid': 'eGolAPPsVeoBAAAAAAAAYA==',\n",
       " '_self': 'dbs/eGolAA==/colls/eGolAPPsVeo=/udfs/eGolAPPsVeoBAAAAAAAAYA==/',\n",
       " '_etag': '\"2101121e-0000-0200-0000-62cb72400000\"',\n",
       " '_ts': 1657500224}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create UDF from a file with JS code\n",
    "def create_udf(client, coll_link, filename):\n",
    "    udf_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    if get_udf(client, coll_link, udf_name):\n",
    "        print(\"UDF\", udf_name, \"already exists, you might want to update it instead\")\n",
    "    else:\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        udf_definition = {\n",
    "            'id': udf_name,\n",
    "            'serverScript': file_contents,\n",
    "        }\n",
    "        return client.CreateUserDefinedFunction(coll_link, udf_definition)\n",
    "\n",
    "# Get UDF by name\n",
    "def get_udf(client, coll_link, udf_name):\n",
    "    udf_query = 'select * from r where r.id =\"' + udf_name + '\"'\n",
    "    udfs = list(client.QueryUserDefinedFunctions(coll_link, udf_query))\n",
    "    if len(udfs) > 0:\n",
    "        return udfs[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "create_udf(client, coll_link, os.path.join(os.getcwd(), 'udf', 'convertToEuro.js'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now verify that the UDF has been properly created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_etag\": \"\\\"2101121e-0000-0200-0000-62cb72400000\\\"\",\n",
      "    \"_rid\": \"eGolAPPsVeoBAAAAAAAAYA==\",\n",
      "    \"_self\": \"dbs/eGolAA==/colls/eGolAPPsVeo=/udfs/eGolAPPsVeoBAAAAAAAAYA==/\",\n",
      "    \"_ts\": 1657500224,\n",
      "    \"body\": \"function convertToEuro(currency_in_usd_text) {\\n    var currency_in_usd_number = Number(currency_in_usd_text.replace(/[^0-9.-]+/g,\\\"\\\"));\\n    currency_in_eur_number = currency_in_usd_number * 0.8898;\\n    currency_in_eur_text = currency_in_eur_number.toLocaleString('en-US', { maximumFractionDigits: 2 })\\n    return \\\"EUR\\\".concat(currency_in_eur_text)\\n}\",\n",
      "    \"id\": \"convertToEuro\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def query_udfs(client, coll_link):\n",
    "    udf_query = 'select * from r'\n",
    "    udfs = list(client.QueryUserDefinedFunctions(coll_link, udf_query))\n",
    "    for udf in udfs:\n",
    "        print(json.dumps(udf, indent=4, sort_keys=True))\n",
    "\n",
    "# Verify the function is created\n",
    "query_udfs(client, coll_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to modify the function (for example if you change the original file), you can use the ReplaceUserDefinedFunction method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update existing UDF with a file\n",
    "def update_udf(client, coll_link, udf_name, filename):\n",
    "    udf_query = 'SELECT * from r WHERE r.id = \"' + udf_name + '\"'\n",
    "    udfs = list(client.QueryUserDefinedFunctions(coll_link, udf_query))\n",
    "    if len(udfs) > 0:\n",
    "        udf_link = udfs[0]['_self']\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        udf_definition = {\n",
    "                    'id': udf_name,\n",
    "                    'body': file_contents,\n",
    "                }\n",
    "        client.ReplaceUserDefinedFunction(udf_link, udf_definition)\n",
    "    else:\n",
    "        print(\"UDF\", udf_name, \"not found!\")\n",
    "\n",
    "update_udf(client, coll_link, 'convertToEuro', os.path.join(os.getcwd(), 'udf', 'convertToEuro.js'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use the function inside of a simple query. Note the higher RU consumption (you can try to execute the same query without the UDF to compare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"balance\": \"$2,701.90\",\n",
      "    \"balanceEUR\": \"EUR2,404.15\",\n",
      "    \"name\": \"Benton Cooley\"\n",
      "}\n",
      "1 items found, 8.7 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT TOP 1 c.name, c.balance, udf.convertToEuro(c.balance) AS balanceEUR FROM customers c WHERE c.source = \"word-of-mouth\"'\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stored procedures\n",
    "\n",
    "The SQL API of Cosmos DB supports stored procedures, that can be used for multiple objectives, such as for example to provide transaction semantics in Cosmos DB. You can find more information in the Cosmos DB documentation about [how to write stored procedures](https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-write-stored-procedures-triggers-udfs#stored-procedures).\n",
    "\n",
    "In this notebook we will use a stored procedure to perform a transfer between the balance of two customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the stored procedure\n",
    "def create_sproc(client, s_coll, filename):\n",
    "    sproc_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    if get_sproc(client, coll_link, sproc_name):\n",
    "        print(\"Stored Procedure\", sproc_name, \"already exists, you might want to update it instead\")\n",
    "    else:\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        sproc_definition = {\n",
    "                    'id': sproc_name,\n",
    "                    'serverScript': file_contents,\n",
    "                }\n",
    "        sproc = client.CreateStoredProcedure(coll_link, sproc_definition)\n",
    "\n",
    "# Get stored procedure by name\n",
    "def get_sproc(client, coll_link, sproc_name):\n",
    "    sproc_query = 'select * from r where r.id =\"' + sproc_name + '\"'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sproc_query))\n",
    "    if len(sprocs) > 0:\n",
    "        return sprocs[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "create_sproc(client, coll_link, os.path.join(os.getcwd(), 'storedproc', 'TransferBalance.js'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that the stored procedure has been created correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_etag\": \"\\\"21014e1e-0000-0200-0000-62cb72510000\\\"\",\n",
      "    \"_rid\": \"eGolAPPsVeoBAAAAAAAAgA==\",\n",
      "    \"_self\": \"dbs/eGolAA==/colls/eGolAPPsVeo=/sprocs/eGolAPPsVeoBAAAAAAAAgA==/\",\n",
      "    \"_ts\": 1657500241,\n",
      "    \"body\": \"function transferBalance(customer_from_id, customer_to_id, amount) {\\n    var context = getContext();\\n    var container = context.getCollection();\\n    var response = context.getResponse();\\n\\n    var customerFromDocument, customerToDocument;\\n\\n    // query for first customer\\n    var filterQuery1 = \\n    {     \\n        'query' : 'SELECT * FROM customers c where c.id = @customer_from_id',\\n        'parameters' : [{'name':'@customer_from_id', 'value':customer_from_id}] \\n    };\\n            \\n    var accept = container.queryDocuments(container.getSelfLink(), filterQuery1, {},\\n        function (err, items, responseOptions) {\\n            if (err) throw new Error(\\\"Error\\\" + err.message);\\n\\n            if (items.length != 1) throw \\\"Unable to find first customer\\\";\\n            customerFromDocument = items[0];\\n\\n            // query for second customer\\n            var filterQuery2 = \\n            {     \\n                'query' : 'SELECT * FROM customers c where c.id = @customer_to_id',\\n                'parameters' : [{'name':'@customer_to_id', 'value':customer_to_id}] \\n            };\\n            var accept2 = container.queryDocuments(container.getSelfLink(), filterQuery2, {},\\n                function (err2, items2, responseOptions2) {\\n                    if (err2) throw new Error(\\\"Error\\\" + err2.message);\\n                    if (items2.length != 1) throw \\\"Unable to find second customer\\\";\\n                    customerToDocument = items2[0];\\n                    transferBalanceDoc(customerFromDocument, customerToDocument, amount);\\n                    return;\\n                });\\n            if (!accept2) throw \\\"Unable to find details for second customer, abort \\\";\\n        });\\n\\n    if (!accept) throw \\\"Unable to find details for first customer, abort \\\";\\n\\n    // function to add or remove USD\\n    function addBalance(balance_text, amount) {\\n        balance_number = Number(balance_text.replace(/[^0-9.-]+/g,\\\"\\\"))\\n        new_balance_number = balance_number + amount\\n        new_balance_text = new_balance_number.toLocaleString('en-US', { maximumFractionDigits: 2 })\\n        return \\\"$\\\".concat(new_balance_text)\\n    }\\n\\n    // swap the two players\\u00e2\\u20ac\\u2122 teams\\n    function transferBalanceDoc(customer_from, customer_to, amount) {\\n        customer_to.balance = addBalance(customer_to.balance, amount);\\n        customer_from.balance = addBalance(customer_from.balance, -1 * amount);\\n\\n        var accept = container.replaceDocument(customer_from._self, customer_from,\\n            function (err, itemReplaced) {\\n                if (err) throw \\\"Unable to update first customer, abort \\\";\\n\\n                var accept2 = container.replaceDocument(customer_to._self, customer_to,\\n                    function (err2, itemReplaced2) {\\n                        if (err) throw \\\"Unable to second customer, abort\\\"\\n                    });\\n\\n                if (!accept2) throw \\\"Unable to update second customer, abort\\\";\\n            });\\n\\n        if (!accept) throw \\\"Unable to update first customer, abort\\\";\\n    }\\n}\",\n",
      "    \"id\": \"TransferBalance\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the list of existing store procedures\n",
    "def query_sproc(client, coll_link):\n",
    "    sp_query = 'select * from r'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sp_query))\n",
    "    for sproc in sprocs:\n",
    "        print(json.dumps(sproc, indent=4, sort_keys=True))\n",
    "\n",
    "query_sproc(client, coll_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to change the stored procedure, you can use this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To update an existing stored procedure\n",
    "def update_sproc(client, coll_link, sproc_name, filename):\n",
    "    sp_query = 'SELECT * from r WHERE r.id = \"' + sproc_name + '\"'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sp_query))\n",
    "    if len(sprocs) > 0:\n",
    "        sproc_link = sprocs[0]['_self']\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        sproc_definition = {\n",
    "                    'id': sproc_name,\n",
    "                    'body': file_contents,\n",
    "                }\n",
    "        client.ReplaceStoredProcedure(sproc_link, sproc_definition)\n",
    "    else:\n",
    "        print(\"Stored procedure\", sproc_name, \"not found!\")\n",
    "\n",
    "update_sproc(client, coll_link, 'TransferBalance', os.path.join(os.getcwd(), 'storedproc', 'TransferBalance.js'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a function to execute the stored procedure, and send some balance from one customer to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute stored procedure\n",
    "def execute_sproc_transferBalance(partition_value, id_from, id_to, amount):\n",
    "    sp_name = 'TransferBalance'\n",
    "    sp_query = 'SELECT * from r WHERE r.id = \"' + sp_name + '\"'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sp_query))\n",
    "    if len(sprocs) > 0:\n",
    "        sproc_link = sprocs[0]['_self']\n",
    "        options = {\n",
    "            'setScriptLoggingEnabled': True,\n",
    "            'partitionKey': partition_value\n",
    "        }\n",
    "        sproc_response = client.ExecuteStoredProcedure(sproc_link, params=[id_from, id_to, amount], options=options)\n",
    "        # The response is the ID of the created resource, not a dictionary as the doc seems to suggest\n",
    "        # https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#executestoredprocedure-sproc-link--params--options-none-\n",
    "        print(type(sproc_response), ':', sproc_response)\n",
    "    else:\n",
    "        print(\"Stored procedure\", sp_name, \"not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally run our transaction using the stored procedure. The following code has two customer IDs in the same partition `word-of-mouth`. When you run the code as-is, you should see that $100 has been transfered from the customer1 (Benton Cooley) to the customer2 (Warren Holman).\n",
    "\n",
    "However, if you uncomment the third line (`id2=\"09d2bb28e9c54bc581492d542789f2ad\"`) you will find receive an error message: `Unable to find second customer`. This is because transactions in Azure Cosmos DB are limited to a single partition, and the ID in this third line corresponds to Giliam Greener, with source='other' and hence in a different subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"balance\": \"$2,701.90\",\n",
      "    \"id\": \"1240d84bd5f44074b36bd1977bc9062c\",\n",
      "    \"name\": \"Benton Cooley\",\n",
      "    \"source\": \"word-of-mouth\"\n",
      "}\n",
      "{\n",
      "    \"balance\": \"$3,490.53\",\n",
      "    \"id\": \"5c89c87d34e64f37a3c8fae3fb86d8fc\",\n",
      "    \"name\": \"Warren Holman\",\n",
      "    \"source\": \"word-of-mouth\"\n",
      "}\n",
      "2 items found, 2.96 RU/s consumed\n",
      "<class 'str'> : \n",
      "{\n",
      "    \"balance\": \"$2,601.9\",\n",
      "    \"id\": \"1240d84bd5f44074b36bd1977bc9062c\",\n",
      "    \"name\": \"Benton Cooley\",\n",
      "    \"source\": \"word-of-mouth\"\n",
      "}\n",
      "{\n",
      "    \"balance\": \"$3,590.53\",\n",
      "    \"id\": \"5c89c87d34e64f37a3c8fae3fb86d8fc\",\n",
      "    \"name\": \"Warren Holman\",\n",
      "    \"source\": \"word-of-mouth\"\n",
      "}\n",
      "2 items found, 2.96 RU/s consumed\n"
     ]
    }
   ],
   "source": [
    "id1=\"1240d84bd5f44074b36bd1977bc9062c\"\n",
    "id2=\"5c89c87d34e64f37a3c8fae3fb86d8fc\"\n",
    "# id2=\"09d2bb28e9c54bc581492d542789f2ad\"\n",
    "amount_to_transfer = 100\n",
    "query = 'SELECT c.name, c.source, c.balance, c.id FROM customers c WHERE c.id IN (\"{0}\", \"{1}\")'.format(id1, id2)\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options=options)\n",
    "execute_sproc_transferBalance('word-of-mouth', id1, id2, amount_to_transfer)\n",
    "send_query(client, coll_link, query, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change feed\n",
    "\n",
    "The change feed is an extremely interesting feature of Cosmos DB, since it enables many usage scenarios such as data replication, triggering serverless computing such as Azure Functions, or cost-effective data deletions, to name a few. You can find more information about Azure Cosmos DB change feed [here](https://docs.microsoft.com/azure/cosmos-db/change-feed).\n",
    "\n",
    "<img src=\"figures/changefeedoverview.png\" width=\"700\"/>\n",
    "\n",
    "The following code shows how to get the change feed from the creation of the database, and how to use the etag header to ask for changes occurred since the last query to the feed, which after creating one document, should be only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 change feed items found, continuation \"58\"\n"
     ]
    }
   ],
   "source": [
    "def get_change_feed(client, coll_link, continuation=None, show_results=True):\n",
    "        options = {}\n",
    "        #options['partitionKeyRangeId'] = ''\n",
    "        if continuation:\n",
    "            options['continuation'] = continuation\n",
    "        else:\n",
    "            options[\"startFromBeginning\"] = True\n",
    "        response = client.QueryItemsChangeFeed(coll_link, options)\n",
    "        if show_results:\n",
    "            i=0\n",
    "            for doc in response:\n",
    "                print(doc)\n",
    "                i += 1\n",
    "            count = i\n",
    "        else:\n",
    "            count = len(tuple(response))\n",
    "        print(count, \"change feed items found, continuation\", client.last_response_headers['etag'])\n",
    "        \n",
    "get_change_feed(client, coll_link, show_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'firstName': 'Sample', 'lastName': 'Person', 'id': 'cr7z61jxdttc2jak', 'source': 'random', '_rid': 'eGolAPPsVeo0AAAAAAAAAA==', '_self': 'dbs/eGolAA==/colls/eGolAPPsVeo=/docs/eGolAPPsVeo0AAAAAAAAAA==/', '_etag': '\"2101b31f-0000-0200-0000-62cb72790000\"', '_attachments': 'attachments/', '_ts': 1657500281, '_lsn': 59}\n",
      "1 change feed items found, continuation \"59\"\n"
     ]
    }
   ],
   "source": [
    "continuation=client.last_response_headers['etag']\n",
    "insert_item(client, coll_link, get_random_item())\n",
    "get_change_feed(client, coll_link, continuation=continuation, show_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have a look at [this sample code](https://github.com/Azure/azure-cosmos-python/blob/master/samples/ChangeFeedManagement/Program.py) for more on handling the Azure Cosmos DB Change feed with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "In order to save costs you can delete the resource group that was created at the beginning of this exercise via the Azure CLI (or any other method). Please be careful with this command, since it will delete the resource group as well as every resource inside, including the Cosmos DB account and all databases and collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az group delete -n $rg -y --no-wait"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 ('azure')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6edd555b2bb1f802423b648148c9fc25716dbd95680d8583052e4c5e1dba0d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
